{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:56:28.807410Z",
     "start_time": "2025-11-02T14:56:28.782114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump, load\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# configs\n",
    "DATA_DIR = Path(\"../data/OCT2017 /train\")  # (kept exactly as you said it's correct)\n",
    "TARGET_SIZE = 128\n",
    "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "BATCH_SIZE = 64  # tune for your RAM / disk\n",
    "RANDOM_STATE = 192\n",
    "\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/tuning_state.pkl\")\n",
    "BEST_MODEL_PATH = Path(\"checkpoints/best_model.pkl\")\n",
    "REPORTS_DIR = Path(\"reports\")\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PDF_PATH = REPORTS_DIR / \"feature_examples.pdf\"\n",
    "\n",
    "# dataloader etc\n",
    "def load_and_preprocess_image(path, target_size=TARGET_SIZE):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    w, h = img.size\n",
    "    scale = target_size / max(w, h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    img = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "    canvas = Image.new(\"RGB\", (target_size, target_size), (255, 255, 255))  # pad with white\n",
    "    canvas.paste(img, ((target_size - new_w) // 2, (target_size - new_h) // 2))\n",
    "    return np.asarray(canvas)\n",
    "\n",
    "def enumerate_paths_and_labels(base_dir=DATA_DIR):\n",
    "    classes = sorted([d.name for d in base_dir.iterdir() if d.is_dir()])\n",
    "    label_map = {name: idx for idx, name in enumerate(classes)}\n",
    "    paths, labels = [], []\n",
    "    for name in classes:\n",
    "        for p in sorted((base_dir / name).glob(\"*\")):\n",
    "            if p.suffix.lower() in IMG_EXTS:\n",
    "                paths.append(p)\n",
    "                labels.append(label_map[name])\n",
    "    y = np.array(labels, dtype=np.int64)\n",
    "    return paths, y, label_map\n",
    "\n",
    "def batch_iterator(paths, indices=None, batch_size=BATCH_SIZE):\n",
    "    if indices is None:\n",
    "        indices = np.arange(len(paths))\n",
    "    n = len(indices)\n",
    "    for i in range(0, n, batch_size):\n",
    "        idxs = indices[i:i+batch_size]\n",
    "        imgs = [load_and_preprocess_image(paths[j]) for j in idxs]\n",
    "        yield np.stack(imgs), idxs\n",
    "\n",
    "# HOG\n",
    "class HOGTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Converts (N, H, W, 3) uint8 images -> (N, F) HOG feature vectors (float64).\n",
    "    \"\"\"\n",
    "    def __init__(self, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm=\"L2-Hys\", visualize=False):\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    "        self.visualize = visualize  # only used for making the PDF examples\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        feats = []\n",
    "        for img in X:\n",
    "            # normalize to float to avoid warnings & match expectations\n",
    "            g = rgb2gray(img.astype(np.float32) / 255.0)\n",
    "            f = hog(\n",
    "                g,\n",
    "                orientations=self.orientations,\n",
    "                pixels_per_cell=self.pixels_per_cell,\n",
    "                cells_per_block=self.cells_per_block,\n",
    "                block_norm=self.block_norm,\n",
    "                feature_vector=True\n",
    "            )\n",
    "            feats.append(f)\n",
    "        return np.vstack(feats)\n",
    "\n",
    "    def transform_with_viz(self, img_single):\n",
    "        \"\"\"Return (features, hog_image) for one image, to visualize in the PDF.\"\"\"\n",
    "        g = rgb2gray(img_single.astype(np.float32) / 255.0)\n",
    "        f, hog_img = hog(\n",
    "            g,\n",
    "            orientations=self.orientations,\n",
    "            pixels_per_cell=self.pixels_per_cell,\n",
    "            cells_per_block=self.cells_per_block,\n",
    "            block_norm=self.block_norm,\n",
    "            visualize=True,\n",
    "            feature_vector=True\n",
    "        )\n",
    "        return f, hog_img\n",
    "\n",
    "# SIFT\n",
    "class SIFTTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extracts SIFT descriptors per image and pools to a fixed-length vector:\n",
    "        feature = concat(mean(desc, axis=0), std(desc, axis=0), [count])\n",
    "    Resulting dimension = 128 + 128 + 1 = 257\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features=0, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6):\n",
    "        # n_features=0 lets SIFT choose; you can clamp e.g., 500 to speed up\n",
    "        self.n_features = n_features\n",
    "        self.contrastThreshold = contrastThreshold\n",
    "        self.edgeThreshold = edgeThreshold\n",
    "        self.sigma = sigma\n",
    "        self._sift = None\n",
    "\n",
    "    def _ensure_sift(self):\n",
    "        if self._sift is None:\n",
    "            if not hasattr(cv2, \"SIFT_create\"):\n",
    "                raise RuntimeError(\n",
    "                    \"SIFT not available in your OpenCV build. Install `opencv-contrib-python`.\"\n",
    "                )\n",
    "            self._sift = cv2.SIFT_create(\n",
    "                nfeatures=self.n_features,\n",
    "                contrastThreshold=self.contrastThreshold,\n",
    "                edgeThreshold=self.edgeThreshold,\n",
    "                sigma=self.sigma\n",
    "            )\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._ensure_sift()\n",
    "        return self\n",
    "\n",
    "    def _img_to_gray(self, img):\n",
    "        if img.ndim == 3 and img.shape[2] == 3:\n",
    "            return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        return img\n",
    "\n",
    "    def transform(self, X):\n",
    "        self._ensure_sift()\n",
    "        out = []\n",
    "        for img in X:\n",
    "            g = self._img_to_gray(img)\n",
    "            kps, desc = self._sift.detectAndCompute(g, None)\n",
    "            if desc is None or len(desc) == 0:\n",
    "                # No keypoints: zeros\n",
    "                mean = np.zeros(128, dtype=np.float32)\n",
    "                std = np.zeros(128, dtype=np.float32)\n",
    "                count = 0.0\n",
    "            else:\n",
    "                mean = desc.mean(axis=0)\n",
    "                std = desc.std(axis=0)\n",
    "                count = float(len(desc))\n",
    "            vec = np.concatenate([mean, std, np.array([count], dtype=np.float32)], axis=0)\n",
    "            out.append(vec.astype(np.float32))\n",
    "        return np.vstack(out)\n",
    "\n",
    "    def detect_keypoints(self, img_single):\n",
    "        \"\"\"Return keypoints for visualization purposes.\"\"\"\n",
    "        self._ensure_sift()\n",
    "        g = self._img_to_gray(img_single)\n",
    "        kps = self._sift.detect(g, None)\n",
    "        return kps\n",
    "\n",
    "# HOG+SIFT\n",
    "class HOGSIFTConcatTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Computes HOG and SIFT features, then concatenates them:\n",
    "      X -> [HOG(X) | SIFT(X)]\n",
    "    Optional per-branch weights let you emphasize one feature family.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hog_params=None,\n",
    "        sift_params=None,\n",
    "        hog_weight=1.0,\n",
    "        sift_weight=1.0,\n",
    "    ):\n",
    "        self.hog_params = hog_params or {}\n",
    "        self.sift_params = sift_params or {}\n",
    "        self.hog_weight = float(hog_weight)\n",
    "        self.sift_weight = float(sift_weight)\n",
    "        self._hog = HOGTransformer(**self.hog_params)\n",
    "        self._sift = SIFTTransformer(**self.sift_params)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Ensure sub-transformers are ready (SIFT alloc)\n",
    "        self._hog.fit(X, y)\n",
    "        self._sift.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        H = self._hog.transform(X).astype(np.float32, copy=False)\n",
    "        S = self._sift.transform(X).astype(np.float32, copy=False)\n",
    "        if self.hog_weight != 1.0:\n",
    "            H = H * self.hog_weight\n",
    "        if self.sift_weight != 1.0:\n",
    "            S = S * self.sift_weight\n",
    "        return np.hstack([H, S]).astype(np.float32, copy=False)\n",
    "\n",
    "def make_pipeline(\n",
    "    feat_type=\"hog\",\n",
    "    hog_params=None,\n",
    "    sift_params=None,\n",
    "    pca_n=None,\n",
    "    C=1.0,\n",
    "    hog_weight=1.0,\n",
    "    sift_weight=1.0,\n",
    "):\n",
    "    if feat_type == \"hog\":\n",
    "        feat = HOGTransformer(**(hog_params or {}))\n",
    "    elif feat_type == \"sift\":\n",
    "        feat = SIFTTransformer(**(sift_params or {}))\n",
    "    elif feat_type in (\"hog+sift\", \"concat\", \"hog_sift\"):\n",
    "        feat = HOGSIFTConcatTransformer(\n",
    "            hog_params=(hog_params or {}),\n",
    "            sift_params=(sift_params or {}),\n",
    "            hog_weight=hog_weight,\n",
    "            sift_weight=sift_weight,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"feat_type must be 'hog', 'sift', or 'hog+sift'\")\n",
    "\n",
    "    steps = [(\"feat\", feat), (\"scaler\", StandardScaler(with_mean=True))]\n",
    "    if pca_n is not None:\n",
    "        steps.append((\"pca\", PCA(n_components=pca_n, svd_solver=\"auto\", random_state=RANDOM_STATE)))\n",
    "    steps.append((\"svm\", LinearSVC(C=C, dual=False, max_iter=10000, random_state=RANDOM_STATE)))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "def _feature_dim_of_transformer(transformer, example_img):\n",
    "    \"\"\"Probe feature dimensionality with one image.\"\"\"\n",
    "    f = transformer.transform(np.expand_dims(example_img, 0))\n",
    "    return f.shape[1]\n",
    "\n",
    "def _build_feats_memmap(n_rows, n_cols, dtype=np.float32):\n",
    "    tmp_dir = Path(\"feature_cache\")\n",
    "    tmp_dir.mkdir(exist_ok=True)\n",
    "    path = tmp_dir / f\"feats_{n_rows}x{n_cols}_{int(time.time())}.dat\"\n",
    "    arr = np.memmap(path, mode=\"w+\", dtype=dtype, shape=(n_rows, n_cols))\n",
    "    return arr, path\n",
    "\n",
    "def _extract_features_batched(paths, indices, transformer, probe_img, batch_size=BATCH_SIZE, pbar_desc=None,\n",
    "                              pbar_position=2, pbar_leave=False):\n",
    "    fdim = _feature_dim_of_transformer(transformer, probe_img)\n",
    "    feats, path = _build_feats_memmap(len(indices), fdim, dtype=np.float32)\n",
    "    write_ptr = 0\n",
    "    desc = pbar_desc or f\"Extract {type(transformer).__name__} (n={len(indices)})\"\n",
    "    with tqdm(total=len(indices), desc=desc, unit=\"img\", position=pbar_position, leave=pbar_leave, dynamic_ncols=True) as pbar:\n",
    "        for Xb, idxs in batch_iterator(paths, indices, batch_size):\n",
    "            Fb = transformer.transform(Xb).astype(np.float32, copy=False)\n",
    "            n = len(idxs)\n",
    "            feats[write_ptr:write_ptr+n] = Fb\n",
    "            write_ptr += n\n",
    "            pbar.update(n)\n",
    "    feats.flush()\n",
    "    return feats, path\n",
    "\n",
    "def fit_eval_pipeline(paths, y, params, cv_splits=5, random_state=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Train/validate one param set using stratified K-fold; returns mean accuracy and per-fold scores.\n",
    "    Featurization happens in batches directly from disk paths.\n",
    "    \"\"\"\n",
    "    feat_type = params[\"feat__type\"]  # \"hog\" or \"sift\" or \"hog+sift\"\n",
    "\n",
    "    if feat_type == \"hog\":\n",
    "        feat_params = dict(\n",
    "            orientations=params[\"hog__orientations\"],\n",
    "            pixels_per_cell=params[\"hog__pixels_per_cell\"],\n",
    "            cells_per_block=params[\"hog__cells_per_block\"],\n",
    "            block_norm=params.get(\"hog__block_norm\", \"L2-Hys\"),\n",
    "        )\n",
    "        transformer = HOGTransformer(**feat_params)\n",
    "\n",
    "    elif feat_type == \"sift\":\n",
    "        feat_params = dict(\n",
    "            n_features=params.get(\"sift__n_features\", 0),\n",
    "            contrastThreshold=params.get(\"sift__contrastThreshold\", 0.04),\n",
    "            edgeThreshold=params.get(\"sift__edgeThreshold\", 10),\n",
    "            sigma=params.get(\"sift__sigma\", 1.6),\n",
    "        )\n",
    "        transformer = SIFTTransformer(**feat_params)\n",
    "\n",
    "    elif feat_type in (\"hog+sift\", \"concat\", \"hog_sift\"):\n",
    "        hogp = dict(\n",
    "            orientations=params[\"hog__orientations\"],\n",
    "            pixels_per_cell=params[\"hog__pixels_per_cell\"],\n",
    "            cells_per_block=params[\"hog__cells_per_block\"],\n",
    "            block_norm=params.get(\"hog__block_norm\", \"L2-Hys\"),\n",
    "        )\n",
    "        siftp = dict(\n",
    "            n_features=params.get(\"sift__n_features\", 0),\n",
    "            contrastThreshold=params.get(\"sift__contrastThreshold\", 0.04),\n",
    "            edgeThreshold=params.get(\"sift__edgeThreshold\", 10),\n",
    "            sigma=params.get(\"sift__sigma\", 1.6),\n",
    "        )\n",
    "        transformer = HOGSIFTConcatTransformer(\n",
    "            hog_params=hogp,\n",
    "            sift_params=siftp,\n",
    "            hog_weight=params.get(\"concat__hog_weight\", 1.0),\n",
    "            sift_weight=params.get(\"concat__sift_weight\", 1.0),\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown feat__type\")\n",
    "\n",
    "    pca_n = params.get(\"pca__n_components\", None)\n",
    "    C = params[\"svm__C\"]\n",
    "\n",
    "    # For probing feature dim, grab one image\n",
    "    probe_img = load_and_preprocess_image(paths[0])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "    fold_scores = []\n",
    "\n",
    "    with tqdm(total=cv_splits, desc=\"CV folds\", position=1, leave=False, dynamic_ncols=True) as foldbar:\n",
    "        for fold_i, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(y)), y), start=1):\n",
    "            transformer.fit(None)  # initialize\n",
    "\n",
    "            Xtr_feats, tr_path = _extract_features_batched(\n",
    "                paths, train_idx, transformer, probe_img,\n",
    "                pbar_desc=f\"Extract {type(transformer).__name__} [train f{fold_i}]\", pbar_position=2,\n",
    "                pbar_leave=False\n",
    "            )\n",
    "            Xval_feats, val_path = _extract_features_batched(\n",
    "                paths, val_idx, transformer, probe_img,\n",
    "                pbar_desc=f\"Extract {type(transformer).__name__} [val   f{fold_i}]\",\n",
    "                pbar_position=3,\n",
    "                pbar_leave=False\n",
    "            )\n",
    "\n",
    "            # Convert to ndarray views\n",
    "            Xtr = np.asarray(Xtr_feats)\n",
    "            Xval = np.asarray(Xval_feats)\n",
    "\n",
    "            # Decide SVM dual based on dimensionality\n",
    "            n_tr, d_tr = Xtr.shape\n",
    "            dual = d_tr > n_tr\n",
    "\n",
    "            steps = [(\"scaler\", StandardScaler(with_mean=True))]\n",
    "            # Clamp PCA to valid range\n",
    "            use_pca_n = None\n",
    "            if pca_n is not None:\n",
    "                max_pca = min(n_tr, d_tr) - 1\n",
    "                if max_pca >= 1 and pca_n <= max_pca:\n",
    "                    use_pca_n = pca_n\n",
    "                else:\n",
    "                    tqdm.write(f\"  -> Skipping PCA (n_components={pca_n} > max={max_pca})\")\n",
    "            if use_pca_n is not None:\n",
    "                steps.append((\"pca\", PCA(n_components=use_pca_n, svd_solver=\"auto\", random_state=random_state)))\n",
    "            steps.append((\"svm\", LinearSVC(C=C, dual=dual, max_iter=10000, random_state=random_state)))\n",
    "            clf = Pipeline(steps)\n",
    "\n",
    "            clf.fit(Xtr, y[train_idx])\n",
    "            preds = clf.predict(Xval)\n",
    "            acc = accuracy_score(y[val_idx], preds)\n",
    "            fold_scores.append(acc)\n",
    "\n",
    "            # Clean up memmaps safely\n",
    "            try:\n",
    "                Xtr_feats.flush(); del Xtr_feats\n",
    "                Xval_feats.flush(); del Xval_feats\n",
    "                del Xtr, Xval\n",
    "                gc.collect()\n",
    "                os.remove(tr_path)\n",
    "                os.remove(val_path)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            foldbar.update(1)\n",
    "\n",
    "    return float(np.mean(fold_scores)), fold_scores\n",
    "\n",
    "def save_state(state_path, state):\n",
    "    tmp = state_path.with_suffix(\".tmp\")\n",
    "    dump(state, tmp)\n",
    "    os.replace(tmp, state_path)\n",
    "\n",
    "def load_state(state_path):\n",
    "    return load(state_path)\n"
   ],
   "id": "68e77a28c6f5792e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:56:33.316391Z",
     "start_time": "2025-11-02T14:56:33.303472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== Post-tuning helpers (plots + final refit) =====================\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pathlib import Path\n",
    "\n",
    "def results_to_dataframe(state: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flatten state['results'] (both successes and errors) into a tidy DataFrame.\n",
    "    Keeps params as columns; tuples/lists are stringified for CSV friendliness.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for r in state.get(\"results\", []):\n",
    "        base = {\n",
    "            \"idx\": r.get(\"idx\"),\n",
    "            \"seconds\": r.get(\"seconds\", np.nan),\n",
    "        }\n",
    "        # Flatten params (tuples -> strings)\n",
    "        params = r.get(\"params\", {})\n",
    "        for k, v in params.items():\n",
    "            base[k] = str(tuple(v)) if isinstance(v, (tuple, list)) else v\n",
    "\n",
    "        # Metrics or error\n",
    "        if \"mean_accuracy\" in r:\n",
    "            base[\"mean_accuracy\"] = float(r[\"mean_accuracy\"])\n",
    "            fs = r.get(\"fold_scores\", [])\n",
    "            base[\"fold_scores\"] = json.dumps([float(x) for x in fs])\n",
    "            base[\"fold_mean\"]   = float(np.mean(fs)) if fs else np.nan\n",
    "            base[\"fold_std\"]    = float(np.std(fs))  if fs else np.nan\n",
    "        else:\n",
    "            base[\"mean_accuracy\"] = np.nan\n",
    "            base[\"error\"] = r.get(\"error\", \"Unknown error\")\n",
    "\n",
    "        rows.append(base)\n",
    "\n",
    "    if not rows:\n",
    "        raise ValueError(\"No results found in state['results'].\")\n",
    "    df = pd.DataFrame(rows).sort_values(\"idx\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_search_figures(df: pd.DataFrame, outdir=\"reports\") -> dict:\n",
    "    \"\"\"\n",
    "    Generate a compact set of figures from the grid search results:\n",
    "      - progress over evaluations\n",
    "      - avg accuracy per feature family\n",
    "      - accuracy vs C (log x), colored by PCA\n",
    "      - runtime vs accuracy\n",
    "      - HOG heatmap (orientations x pixels_per_cell) if available\n",
    "    Saves one PDF + individual PNGs + a CSV with top 20 rows.\n",
    "\n",
    "    Returns dict with saved paths.\n",
    "    \"\"\"\n",
    "    outdir = Path(outdir)\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pdf_path = outdir / \"gridsearch_summary.pdf\"\n",
    "    created_pngs = []\n",
    "\n",
    "    plt.ioff()  # headless-friendly\n",
    "\n",
    "    dff = df.dropna(subset=[\"mean_accuracy\"]).copy()\n",
    "\n",
    "    # A) progress\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    dff_sorted = dff.sort_values(\"idx\")\n",
    "    plt.plot(dff_sorted[\"idx\"], dff_sorted[\"mean_accuracy\"], marker=\"o\", lw=1)\n",
    "    plt.xlabel(\"Evaluation index\")\n",
    "    plt.ylabel(\"Mean CV accuracy\")\n",
    "    plt.title(\"Grid search progress\")\n",
    "    plt.grid(True, ls=\"--\", alpha=0.3)\n",
    "    created_pngs.append((\"progress\", fig))\n",
    "\n",
    "    # B) accuracy by feature type\n",
    "    if \"feat__type\" in dff.columns:\n",
    "        fig = plt.figure(figsize=(7, 4))\n",
    "        agg = dff.groupby(\"feat__type\")[\"mean_accuracy\"].agg([\"mean\", \"max\", \"count\"]).sort_values(\"mean\", ascending=False)\n",
    "        plt.bar(agg.index, agg[\"mean\"])\n",
    "        plt.ylabel(\"Mean CV accuracy\")\n",
    "        plt.title(\"Average accuracy per feature type\")\n",
    "        created_pngs.append((\"acc_by_feat_type\", fig))\n",
    "\n",
    "    # C) accuracy vs C\n",
    "    if \"svm__C\" in dff.columns:\n",
    "        fig = plt.figure(figsize=(7, 5))\n",
    "        sub = dff.copy()\n",
    "        if \"pca__n_components\" in sub.columns:\n",
    "            pcs = sorted([p for p in sub[\"pca__n_components\"].dropna().unique()])\n",
    "            for p in pcs:\n",
    "                ss = sub[sub[\"pca__n_components\"] == p]\n",
    "                plt.scatter(ss[\"svm__C\"], ss[\"mean_accuracy\"], label=f\"PCA={int(p)}\", s=40)\n",
    "            nopca = sub[sub[\"pca__n_components\"].isna()]\n",
    "            if not nopca.empty:\n",
    "                plt.scatter(nopca[\"svm__C\"], nopca[\"mean_accuracy\"], label=\"PCA=None\", s=50, marker=\"x\")\n",
    "            if pcs or not nopca.empty:\n",
    "                plt.legend()\n",
    "        else:\n",
    "            plt.scatter(sub[\"svm__C\"], sub[\"mean_accuracy\"], s=40)\n",
    "        try:\n",
    "            plt.xscale(\"log\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        plt.xlabel(\"C\")\n",
    "        plt.ylabel(\"Mean CV accuracy\")\n",
    "        plt.title(\"Accuracy vs C\")\n",
    "        plt.grid(True, ls=\"--\", alpha=0.3)\n",
    "        created_pngs.append((\"acc_vs_C\", fig))\n",
    "\n",
    "    # D) runtime vs accuracy\n",
    "    if \"seconds\" in dff.columns:\n",
    "        fig = plt.figure(figsize=(7, 5))\n",
    "        plt.scatter(dff[\"seconds\"], dff[\"mean_accuracy\"], s=40)\n",
    "        plt.xlabel(\"Seconds per evaluation\")\n",
    "        plt.ylabel(\"Mean CV accuracy\")\n",
    "        plt.title(\"Runtime vs accuracy\")\n",
    "        plt.grid(True, ls=\"--\", alpha=0.3)\n",
    "        created_pngs.append((\"time_vs_acc\", fig))\n",
    "\n",
    "    # E) HOG heatmap (max accuracy over cells_per_block/others)\n",
    "    if set([\"hog__orientations\", \"hog__pixels_per_cell\"]).issubset(dff.columns):\n",
    "        try:\n",
    "            sub = dff.copy()\n",
    "            sub[\"hog__pixels_per_cell\"] = sub[\"hog__pixels_per_cell\"].astype(str)\n",
    "            piv = sub.pivot_table(\n",
    "                index=\"hog__orientations\",\n",
    "                columns=\"hog__pixels_per_cell\",\n",
    "                values=\"mean_accuracy\",\n",
    "                aggfunc=\"max\",\n",
    "            )\n",
    "            fig = plt.figure(figsize=(8, 5))\n",
    "            im = plt.imshow(piv.values, aspect=\"auto\")\n",
    "            plt.colorbar(im, fraction=0.046, pad=0.04, label=\"Mean CV accuracy (max)\")\n",
    "            plt.xticks(np.arange(piv.shape[1]), piv.columns, rotation=0)\n",
    "            plt.yticks(np.arange(piv.shape[0]), piv.index)\n",
    "            plt.xlabel(\"pixels_per_cell\")\n",
    "            plt.ylabel(\"orientations\")\n",
    "            plt.title(\"HOG — max accuracy by (orientations × pixels_per_cell)\")\n",
    "            created_pngs.append((\"hog_heatmap\", fig))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipped HOG heatmap: {e}\")\n",
    "\n",
    "    # Save one PDF with all figs + individual PNGs\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        for name, fig in created_pngs:\n",
    "            fig.tight_layout()\n",
    "            pdf.savefig(fig)\n",
    "            fig.savefig(outdir / f\"{name}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "\n",
    "    # Top-20 table\n",
    "    top20_path = outdir / \"top20_results.csv\"\n",
    "    dff.sort_values(\"mean_accuracy\", ascending=False).head(20).to_csv(top20_path, index=False)\n",
    "\n",
    "    print(f\"[PLOTS] Saved: {pdf_path}\")\n",
    "    return {\n",
    "        \"pdf\": str(pdf_path),\n",
    "        \"pngs\": [str(outdir / f\"{name}.png\") for name, _ in created_pngs],\n",
    "        \"top20_csv\": str(top20_path),\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_best_params(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Return the row (as dict) of the best mean_accuracy.\"\"\"\n",
    "    dff = df.dropna(subset=[\"mean_accuracy\"])\n",
    "    if dff.empty:\n",
    "        raise ValueError(\"No successful runs with mean_accuracy.\")\n",
    "    best = dff.loc[dff[\"mean_accuracy\"].idxmax()].to_dict()\n",
    "    # Keep only hyperparameter keys (contain '__')\n",
    "    best_params = {k: best[k] for k in best.keys() if \"__\" in k}\n",
    "    # Convert stringified tuples back where relevant\n",
    "    # (Only the ones your code expects as tuples)\n",
    "    def _maybe_tuple(x):\n",
    "        if isinstance(x, str) and x.startswith(\"(\") and x.endswith(\")\"):\n",
    "            try:\n",
    "                return eval(x)\n",
    "            except Exception:\n",
    "                return x\n",
    "        return x\n",
    "    for k in list(best_params.keys()):\n",
    "        best_params[k] = _maybe_tuple(best_params[k])\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def refit_on_full(paths, y, best_params: dict, best_model_path=\"checkpoints/best_model.pkl\"):\n",
    "    \"\"\"\n",
    "    Recompute features on ALL data for the selected hyperparams and fit the\n",
    "    scaler/[optional PCA]/LinearSVC pipeline once. Saves to best_model_path.\n",
    "    \"\"\"\n",
    "    best_model_path = Path(best_model_path)\n",
    "    best_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    feat_type = best_params[\"feat__type\"]\n",
    "\n",
    "    if feat_type == \"hog\":\n",
    "        feat_params = dict(\n",
    "            orientations=best_params[\"hog__orientations\"],\n",
    "            pixels_per_cell=best_params[\"hog__pixels_per_cell\"],\n",
    "            cells_per_block=best_params[\"hog__cells_per_block\"],\n",
    "            block_norm=best_params.get(\"hog__block_norm\", \"L2-Hys\"),\n",
    "        )\n",
    "        transformer = HOGTransformer(**feat_params)\n",
    "        save_feat_params = feat_params\n",
    "\n",
    "    elif feat_type == \"sift\":\n",
    "        feat_params = dict(\n",
    "            n_features=best_params.get(\"sift__n_features\", 0),\n",
    "            contrastThreshold=best_params.get(\"sift__contrastThreshold\", 0.04),\n",
    "            edgeThreshold=best_params.get(\"sift__edgeThreshold\", 10),\n",
    "            sigma=best_params.get(\"sift__sigma\", 1.6),\n",
    "        )\n",
    "        transformer = SIFTTransformer(**feat_params)\n",
    "        save_feat_params = feat_params\n",
    "\n",
    "    elif feat_type in (\"hog+sift\", \"concat\", \"hog_sift\"):\n",
    "        hogp = dict(\n",
    "            orientations=best_params[\"hog__orientations\"],\n",
    "            pixels_per_cell=best_params[\"hog__pixels_per_cell\"],\n",
    "            cells_per_block=best_params[\"hog__cells_per_block\"],\n",
    "            block_norm=best_params.get(\"hog__block_norm\", \"L2-Hys\"),\n",
    "        )\n",
    "        siftp = dict(\n",
    "            n_features=best_params.get(\"sift__n_features\", 0),\n",
    "            contrastThreshold=best_params.get(\"sift__contrastThreshold\", 0.04),\n",
    "            edgeThreshold=best_params.get(\"sift__edgeThreshold\", 10),\n",
    "            sigma=best_params.get(\"sift__sigma\", 1.6),\n",
    "        )\n",
    "        transformer = HOGSIFTConcatTransformer(\n",
    "            hog_params=hogp,\n",
    "            sift_params=siftp,\n",
    "            hog_weight=best_params.get(\"concat__hog_weight\", 1.0),\n",
    "            sift_weight=best_params.get(\"concat__sift_weight\", 1.0),\n",
    "        )\n",
    "        save_feat_params = {\n",
    "            \"hog_params\": hogp, \"sift_params\": siftp,\n",
    "            \"hog_weight\": best_params.get(\"concat__hog_weight\", 1.0),\n",
    "            \"sift_weight\": best_params.get(\"concat__sift_weight\", 1.0),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown feat__type: {feat_type}\")\n",
    "\n",
    "    # Features on all data (batched)\n",
    "    probe_img = load_and_preprocess_image(paths[0])\n",
    "    transformer.fit(None)\n",
    "    all_indices = np.arange(len(paths))\n",
    "    X_feats, feats_path = _extract_features_batched(\n",
    "        paths, all_indices, transformer, probe_img,\n",
    "        pbar_desc=\"Extract features [full refit]\",\n",
    "        pbar_position=1, pbar_leave=False\n",
    "    )\n",
    "\n",
    "    X_all = np.asarray(X_feats)\n",
    "    n_all, d_all = X_all.shape\n",
    "    dual = d_all > n_all\n",
    "\n",
    "    # Post-feature pipeline\n",
    "    steps = [(\"scaler\", StandardScaler(with_mean=True))]\n",
    "    pca_n = best_params.get(\"pca__n_components\", None)\n",
    "    if pca_n is not None:\n",
    "        max_pca = min(n_all, d_all) - 1\n",
    "        if max_pca >= 1 and pca_n <= max_pca:\n",
    "            steps.append((\"pca\", PCA(n_components=pca_n, svd_solver=\"auto\", random_state=RANDOM_STATE)))\n",
    "        else:\n",
    "            print(f\"[Refit] Skipping PCA (n_components={pca_n} > max={max_pca})\")\n",
    "    steps.append((\"svm\", LinearSVC(C=best_params[\"svm__C\"], dual=dual, max_iter=10000, random_state=RANDOM_STATE)))\n",
    "    final_pipe = Pipeline(steps)\n",
    "    final_pipe.fit(X_all, y)\n",
    "\n",
    "    dump({\n",
    "        \"feature_type\": feat_type,\n",
    "        \"feature_params\": save_feat_params,\n",
    "        \"post_feat_pipeline\": final_pipe\n",
    "    }, best_model_path)\n",
    "\n",
    "    # Cleanup memmap\n",
    "    try:\n",
    "        X_feats.flush(); del X_feats; del X_all\n",
    "        gc.collect()\n",
    "        os.remove(feats_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(f\"[Refit] Saved final model to: {best_model_path}\")\n",
    "    return str(best_model_path)\n"
   ],
   "id": "5f0fc7c804042ab4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:56:35.677612Z",
     "start_time": "2025-11-02T14:56:35.147669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state2 = load(CHECKPOINT_PATH)\n",
    "df2 = results_to_dataframe(state2)\n",
    "plot_search_figures(df2, REPORTS_DIR)"
   ],
   "id": "c2c4c7700456dcb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PLOTS] Saved: reports/gridsearch_summary.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pdf': 'reports/gridsearch_summary.pdf',\n",
       " 'pngs': ['reports/progress.png',\n",
       "  'reports/acc_by_feat_type.png',\n",
       "  'reports/acc_vs_C.png',\n",
       "  'reports/time_vs_acc.png',\n",
       "  'reports/hog_heatmap.png'],\n",
       " 'top20_csv': 'reports/top20_results.csv'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:33:16.734162Z",
     "start_time": "2025-11-02T15:33:16.730886Z"
    }
   },
   "cell_type": "code",
   "source": "print(df2.head())",
   "id": "88c84dbb7d99b89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   idx     seconds feat__type hog__block_norm hog__cells_per_block  \\\n",
      "0    0  208.174597        hog          L2-Hys               (2, 2)   \n",
      "1    1  205.430000        hog          L2-Hys               (2, 2)   \n",
      "2    2  206.480794        hog          L2-Hys               (2, 2)   \n",
      "3    3  206.286557        hog          L2-Hys               (2, 2)   \n",
      "4    4  202.956786        hog          L2-Hys               (2, 2)   \n",
      "\n",
      "   hog__orientations hog__pixels_per_cell  pca__n_components  svm__C  \\\n",
      "0                6.0               (8, 8)                128   0.002   \n",
      "1                6.0               (8, 8)                128   0.250   \n",
      "2                6.0               (8, 8)                128   1.000   \n",
      "3                6.0               (8, 8)                128   4.000   \n",
      "4                6.0               (8, 8)                256   0.002   \n",
      "\n",
      "   mean_accuracy                               fold_scores  fold_mean  \\\n",
      "0       0.757786  [0.7569477719214183, 0.7586248203162435]   0.757786   \n",
      "1       0.758206  [0.7571873502635362, 0.7592237661715381]   0.758206   \n",
      "2       0.758206  [0.7571873502635362, 0.7592237661715381]   0.758206   \n",
      "3       0.758206  [0.7571873502635362, 0.7592237661715381]   0.758206   \n",
      "4       0.763776  [0.7622184954480115, 0.7653330138955439]   0.763776   \n",
      "\n",
      "   fold_std  sift__contrastThreshold  sift__edgeThreshold  sift__n_features  \\\n",
      "0  0.000839                      NaN                  NaN               NaN   \n",
      "1  0.001018                      NaN                  NaN               NaN   \n",
      "2  0.001018                      NaN                  NaN               NaN   \n",
      "3  0.001018                      NaN                  NaN               NaN   \n",
      "4  0.001557                      NaN                  NaN               NaN   \n",
      "\n",
      "   sift__sigma  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:32:12.163944Z",
     "start_time": "2025-11-02T15:32:12.146461Z"
    }
   },
   "cell_type": "code",
   "source": "df2.to_csv('gridsearch.csv', index=False)",
   "id": "a49f322cf9aeaeb7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:34:13.339034Z",
     "start_time": "2025-11-02T15:34:13.336160Z"
    }
   },
   "cell_type": "code",
   "source": "sift_df = df2[df2[\"feat__type\"] == \"sift\"]",
   "id": "1ce8ecbd93bcaa01",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:34:26.739220Z",
     "start_time": "2025-11-02T15:34:26.736449Z"
    }
   },
   "cell_type": "code",
   "source": "best_sift = sift_df.loc[sift_df[\"mean_accuracy\"].idxmax()]",
   "id": "b148d2f29cec5ceb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T15:37:03.262425Z",
     "start_time": "2025-11-02T15:37:03.258393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_sift[[\"sift__n_features\", \"sift__contrastThreshold\",\n",
    "           \"sift__edgeThreshold\", \"sift__sigma\", \"mean_accuracy\", \"svm__C\"]]"
   ],
   "id": "14e46d9a9296445e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sift__n_features                0.0\n",
       "sift__contrastThreshold        0.02\n",
       "sift__edgeThreshold            15.0\n",
       "sift__sigma                     1.2\n",
       "mean_accuracy              0.771083\n",
       "svm__C                         0.25\n",
       "Name: 541, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8ae8cb63ee07e6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
